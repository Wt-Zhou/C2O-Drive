from __future__ import annotations
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
import numpy as np
import math


@dataclass
class DirichletParams:
    """ç©ºé—´ Dirichlet å‚æ•°é…ç½®ã€‚
    
    Attributes:
        alpha_in: å¯è¾¾é›†åˆå†…çš„å…ˆéªŒä¼ªè®¡æ•°ï¼Œé»˜è®¤ 50.0
        alpha_out: å¯è¾¾é›†åˆå¤–çš„å…ˆéªŒä¼ªè®¡æ•°ï¼Œé»˜è®¤ 1e-6
        delta: ç½®ä¿¡æ°´å¹³å‚æ•°ï¼Œé»˜è®¤ 0.05
        cK: ç½®ä¿¡åŠå¾„æ ¡å‡†å¸¸æ•°ï¼Œé»˜è®¤ 1.0
    """
    alpha_in: float = 50.0
    alpha_out: float = 1e-6
    delta: float = 0.05
    cK: float = 1.0


class SpatialDirichletBank:
    """ç»´æŠ¤æ¯ä¸ªæ™ºèƒ½ä½“çš„ç©ºé—´ Dirichlet åˆ†å¸ƒï¼Œæ”¯æŒä¸€æ­¥è½¬ç§»æ¦‚ç‡å»ºæ¨¡ã€‚
    
    ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“ç»´æŠ¤ä¸€ä¸ª K ç»´çš„ Dirichlet ä¼ªè®¡æ•°å‘é‡ alpha_i âˆˆ R^K_+ï¼Œ
    è¡¨ç¤ºè¯¥æ™ºèƒ½ä½“åœ¨å„ç½‘æ ¼å•å…ƒä¸Šçš„å æ®æ¦‚ç‡åˆ†å¸ƒã€‚
    """

    def __init__(self, K: int, params: DirichletParams) -> None:
        """åˆå§‹åŒ–ç©ºé—´ Dirichlet é“¶è¡Œã€‚
        
        Args:
            K: ç½‘æ ¼å•å…ƒæ€»æ•°
            params: Dirichlet å‚æ•°é…ç½®
        """
        assert K > 0, "Grid size K must be positive"
        assert params.alpha_in > 0, "alpha_in must be positive"
        assert params.alpha_out > 0, "alpha_out must be positive"
        assert 0 < params.delta < 1, "delta must be in (0, 1)"
        
        self.K = K
        self.params = params
        self.agent_alphas: Dict[int, np.ndarray] = {}

    def init_agent(self, agent_id: int, reachable: List[int]) -> None:
        """ä¸ºæ™ºèƒ½ä½“åˆå§‹åŒ– Dirichlet å…ˆéªŒåˆ†å¸ƒã€‚
        
        åœ¨å¯è¾¾é›†åˆå†…å‡åŒ€åˆ†é… alpha_inï¼Œå…¶ä½™ä½ç½®è®¾ä¸º alpha_outã€‚
        
        Args:
            agent_id: æ™ºèƒ½ä½“ ID
            reachable: å¯è¾¾ç½‘æ ¼å•å…ƒç´¢å¼•åˆ—è¡¨
        """
        assert len(reachable) > 0, "Reachable set cannot be empty"
        assert all(0 <= idx < self.K for idx in reachable), "Reachable indices out of range"
        
        alpha = np.full(self.K, self.params.alpha_out, dtype=float)
        
        # åœ¨å¯è¾¾é›†åˆå†…å‡åŒ€åˆ†é… alpha_in
        alpha_per_cell = self.params.alpha_in / len(reachable)
        for idx in reachable:
            alpha[idx] = alpha_per_cell
        
        self.agent_alphas[agent_id] = alpha

    def ensure_agent(self, agent_id: int, reachable: List[int]) -> None:
        """ç¡®ä¿æ™ºèƒ½ä½“å·²åˆå§‹åŒ–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆå§‹åŒ–ã€‚
        
        Args:
            agent_id: æ™ºèƒ½ä½“ ID
            reachable: å¯è¾¾ç½‘æ ¼å•å…ƒç´¢å¼•åˆ—è¡¨
        """
        if agent_id not in self.agent_alphas:
            self.init_agent(agent_id, reachable)

    def update_with_softcount(self, agent_id: int, w: np.ndarray, lr: float = 1.0) -> None:
        """ä½¿ç”¨è½¯è®¡æ•°æ›´æ–°æ™ºèƒ½ä½“çš„ Dirichlet åˆ†å¸ƒã€‚
        
        æ‰§è¡Œå…±è½­æ›´æ–°ï¼šalpha += lr * w
        
        Args:
            agent_id: æ™ºèƒ½ä½“ ID
            w: è½¯è®¡æ•°æƒé‡å‘é‡ï¼Œå½¢çŠ¶ (K,)ï¼Œè¦æ±‚ sum(w) â‰ˆ 1
            lr: å­¦ä¹ ç‡ï¼Œé»˜è®¤ 1.0
        """
        assert agent_id in self.agent_alphas, f"Agent {agent_id} not initialized"
        assert w.shape == (self.K,), f"Weight shape {w.shape} != ({self.K},)"
        assert np.abs(w.sum() - 1.0) < 1e-6, f"Weights sum {w.sum()} != 1.0"
        assert lr > 0, "Learning rate must be positive"
        
        self.agent_alphas[agent_id] += lr * w

    def posterior_mean(self, agent_id: int) -> np.ndarray:
        """è®¡ç®—æ™ºèƒ½ä½“çš„åéªŒæœŸæœ›æ¦‚ç‡åˆ†å¸ƒã€‚
        
        è¿”å› E[p] = alpha / alpha.sum() under Dirichlet(alpha)
        
        Args:
            agent_id: æ™ºèƒ½ä½“ ID
            
        Returns:
            å½¢çŠ¶ (K,) çš„æ¦‚ç‡å‘é‡ï¼Œæ»¡è¶³ sum(p) = 1
        """
        assert agent_id in self.agent_alphas, f"Agent {agent_id} not initialized"
        
        alpha = self.agent_alphas[agent_id]
        return alpha / alpha.sum()

    def l1_radius(self, agent_id: int) -> float:
        """è®¡ç®—æ™ºèƒ½ä½“åˆ†å¸ƒçš„ L1 ç½®ä¿¡åŠå¾„ã€‚
        
        ä½¿ç”¨è¿‘ä¼¼å…¬å¼ï¼šr â‰ˆ cK * sqrt(2*log(1/Î´)/Î±â‚€)
        å…¶ä¸­ Î±â‚€ = sum(alpha) æ˜¯æ€»ä¼ªè®¡æ•°ã€‚
        
        Args:
            agent_id: æ™ºèƒ½ä½“ ID
            
        Returns:
            ç½®ä¿¡åŠå¾„å€¼
        """
        assert agent_id in self.agent_alphas, f"Agent {agent_id} not initialized"
        
        alpha = self.agent_alphas[agent_id]
        alpha_0 = alpha.sum()
        
        if alpha_0 <= 1e-12:
            return 1.0  # é€€åŒ–æƒ…å†µ
            
        log_term = math.log(1.0 / self.params.delta)
        radius = self.params.cK * math.sqrt(2 * log_term / alpha_0)
        
        return radius

    def conservative_qmax_union(self, agent_ids: List[int]) -> np.ndarray:
        """è®¡ç®—å¤šæ™ºèƒ½ä½“çš„ä¿å®ˆä¸Šç•Œå æ®æ¦‚ç‡å›¾ã€‚
        
        å¯¹æ¯ä¸ªç½‘æ ¼å•å…ƒ gï¼Œè®¡ç®—ï¼š
        q_max(g) = clip(Î£áµ¢ min(1, pÌ‚áµ¢(g) + 0.5*ráµ¢), 0, 1)
        
        å…¶ä¸­ pÌ‚áµ¢(g) æ˜¯æ™ºèƒ½ä½“ i åœ¨å•å…ƒ g çš„åéªŒæœŸæœ›ï¼Œráµ¢ æ˜¯å…¶ç½®ä¿¡åŠå¾„ã€‚
        
        Args:
            agent_ids: æ™ºèƒ½ä½“ ID åˆ—è¡¨
            
        Returns:
            å½¢çŠ¶ (K,) çš„ä¸Šç•Œå æ®æ¦‚ç‡å‘é‡ï¼Œå€¼åŸŸ [0, 1]
        """
        assert len(agent_ids) > 0, "Agent list cannot be empty"
        assert all(agent_id in self.agent_alphas for agent_id in agent_ids), \
            "All agents must be initialized"
        
        q_max = np.zeros(self.K, dtype=float)
        
        for agent_id in agent_ids:
            p_mean = self.posterior_mean(agent_id)
            radius = self.l1_radius(agent_id)
            
            # æ·»åŠ ä¿å®ˆé¡¹ï¼špÌ‚áµ¢(g) + 0.5*ráµ¢ï¼Œç„¶å clip åˆ° [0,1]
            conservative_p = np.clip(p_mean + 0.5 * radius, 0.0, 1.0)
            q_max += conservative_p
        
        # æœ€ç»ˆ clip åˆ° [0,1]
        return np.clip(q_max, 0.0, 1.0)

    def get_agent_alpha(self, agent_id: int) -> np.ndarray:
        """è·å–æ™ºèƒ½ä½“çš„å½“å‰ alpha å‘é‡ï¼ˆç”¨äºè°ƒè¯•ï¼‰ã€‚
        
        Args:
            agent_id: æ™ºèƒ½ä½“ ID
            
        Returns:
            å½¢çŠ¶ (K,) çš„ alpha å‘é‡
        """
        assert agent_id in self.agent_alphas, f"Agent {agent_id} not initialized"
        return self.agent_alphas[agent_id].copy()

    def get_agent_count(self) -> int:
        """è·å–å·²åˆå§‹åŒ–çš„æ™ºèƒ½ä½“æ•°é‡ã€‚
        
        Returns:
            æ™ºèƒ½ä½“æ•°é‡
        """
        return len(self.agent_alphas)

    def get_agent_counts(self, agent_id: int, subtract_prior: bool = True) -> np.ndarray:
        """è·å–æ™ºèƒ½ä½“çš„è®¡æ•°å‘é‡ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰ã€‚
        
        Args:
            agent_id: æ™ºèƒ½ä½“ ID
            subtract_prior: æ˜¯å¦å‡å»å…ˆéªŒå€¼ï¼ˆåˆå§‹alphaï¼‰
            
        Returns:
            å½¢çŠ¶ (K,) çš„è®¡æ•°å‘é‡
        """
        assert agent_id in self.agent_alphas, f"Agent {agent_id} not initialized"
        
        alpha = self.agent_alphas[agent_id]
        
        if subtract_prior:
            # å‡å»åˆå§‹alphaå€¼ï¼Œå¾—åˆ°å®é™…çš„è§‚æµ‹è®¡æ•°
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦çŸ¥é“åˆå§‹alphaå€¼ï¼Œæš‚æ—¶ç”¨ç®€å•ä¼°è®¡
            # å¯¹äºå¯è¾¾é›†å†…çš„å•å…ƒï¼Œåˆå§‹å€¼åº”è¯¥æ˜¯ alpha_in / len(reachable)
            # å¯¹äºå¯è¾¾é›†å¤–çš„å•å…ƒï¼Œåˆå§‹å€¼åº”è¯¥æ˜¯ alpha_out
            # ç”±äºæˆ‘ä»¬æ²¡æœ‰å­˜å‚¨åˆå§‹reachableä¿¡æ¯ï¼Œè¿™é‡Œç”¨ç®€å•æ–¹æ³•
            alpha_init = np.full_like(alpha, self.params.alpha_out)
            # å‡è®¾å‰å‡ ä¸ªéé›¶ä½ç½®æ˜¯å¯è¾¾é›†ï¼ˆè¿™æ˜¯ä¸€ä¸ªç®€åŒ–ï¼‰
            nonzero_indices = np.nonzero(alpha > self.params.alpha_out)[0]
            if len(nonzero_indices) > 0:
                # ç®€å•ä¼°è®¡ï¼šå‡è®¾åˆå§‹æ—¶å¯è¾¾é›†å†…å‡åŒ€åˆ†å¸ƒ
                alpha_init[nonzero_indices] = self.params.alpha_in / len(nonzero_indices)
            
            return alpha - alpha_init
        else:
            return alpha.copy()


class MultiTimestepSpatialDirichletBank:
    """ç»´æŠ¤æ¯ä¸ªæ™ºèƒ½ä½“åœ¨å¤šä¸ªæ—¶é—´æ­¥çš„ç©ºé—´Dirichletåˆ†å¸ƒã€‚
    
    ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“åœ¨æ¯ä¸ªæ—¶é—´æ­¥ç»´æŠ¤ä¸€ä¸ªç‹¬ç«‹çš„Kç»´Dirichletä¼ªè®¡æ•°å‘é‡ï¼Œ
    æ”¯æŒå¤šæ—¶é—´æ­¥è½¬ç§»æ¦‚ç‡å»ºæ¨¡ã€‚
    """

    def __init__(self, K: int, params: DirichletParams, horizon: Optional[int] = None) -> None:
        """åˆå§‹åŒ–å¤šæ—¶é—´æ­¥ç©ºé—´Dirichleté“¶è¡Œã€‚

        Args:
            K: ç½‘æ ¼å•å…ƒæ€»æ•°
            params: Dirichletå‚æ•°é…ç½®
            horizon: é¢„æµ‹æ—¶é—´æ­¥æ•°ï¼ˆNone = ä»å…¨å±€é…ç½®è¯»å–ï¼‰
        """
        assert K > 0, "Grid size K must be positive"

        # Load horizon from global config if not specified
        if horizon is None:
            from c2o_drive.config import get_global_config
            horizon = get_global_config().time.default_horizon

        assert horizon > 0, "Horizon must be positive"

        self.K = K
        self.params = params
        self.horizon = horizon
        
        # æ¯ä¸ªæ™ºèƒ½ä½“åœ¨æ¯ä¸ªæ—¶é—´æ­¥çš„alphaå‚æ•°
        # agent_alphas[agent_id][timestep] = alpha_vector
        self.agent_alphas: Dict[int, Dict[int, np.ndarray]] = {}

    def init_agent(self, agent_id: int, reachable_sets: Dict[int, List[int]]) -> None:
        """ä¸ºæ™ºèƒ½ä½“åœ¨æ‰€æœ‰æ—¶é—´æ­¥åˆå§‹åŒ–Dirichletå…ˆéªŒåˆ†å¸ƒã€‚
        
        Args:
            agent_id: æ™ºèƒ½ä½“ID
            reachable_sets: {timestep: [reachable_cell_indices]}
        """
        self.agent_alphas[agent_id] = {}
        
        for timestep in range(1, self.horizon + 1):
            alpha = np.full(self.K, self.params.alpha_out, dtype=float)
            
            if timestep in reachable_sets:
                reachable = reachable_sets[timestep]
                if len(reachable) > 0:
                    alpha_in_per_cell = self.params.alpha_in / len(reachable)
                    for cell_idx in reachable:
                        if 0 <= cell_idx < self.K:
                            alpha[cell_idx] = alpha_in_per_cell
            
            self.agent_alphas[agent_id][timestep] = alpha

    def update_with_softcount(self, agent_id: int, timestep: int, w: np.ndarray, lr: float = 1.0) -> None:
        """ä½¿ç”¨è½¯è®¡æ•°æ›´æ–°æŒ‡å®šæ—¶é—´æ­¥çš„Dirichletå‚æ•°ã€‚
        
        Args:
            agent_id: æ™ºèƒ½ä½“ID
            timestep: æ—¶é—´æ­¥
            w: è½¯è®¡æ•°å‘é‡ (Kç»´)
            lr: å­¦ä¹ ç‡
        """
        if agent_id not in self.agent_alphas:
            raise ValueError(f"Agent {agent_id} not initialized")
        
        if timestep not in self.agent_alphas[agent_id]:
            raise ValueError(f"Timestep {timestep} not initialized for agent {agent_id}")
        
        # æ›´æ–°alphaå‚æ•°ï¼šalpha_new = alpha_old + lr * w
        self.agent_alphas[agent_id][timestep] += lr * w

    def get_agent_alpha(self, agent_id: int, timestep: int) -> np.ndarray:
        """è·å–æ™ºèƒ½ä½“åœ¨æŒ‡å®šæ—¶é—´æ­¥çš„alphaå‚æ•°ã€‚"""
        if agent_id not in self.agent_alphas:
            raise ValueError(f"Agent {agent_id} not initialized")
        
        if timestep not in self.agent_alphas[agent_id]:
            raise ValueError(f"Timestep {timestep} not initialized for agent {agent_id}")
        
        return self.agent_alphas[agent_id][timestep].copy()

    def posterior_mean(self, agent_id: int, timestep: int) -> np.ndarray:
        """è®¡ç®—æ™ºèƒ½ä½“åœ¨æŒ‡å®šæ—¶é—´æ­¥çš„åéªŒå‡å€¼æ¦‚ç‡ã€‚"""
        alpha = self.get_agent_alpha(agent_id, timestep)
        return alpha / alpha.sum()

    def sample_trajectory(self, agent_id: int) -> Dict[int, np.ndarray]:
        """ä»æ™ºèƒ½ä½“çš„å¤šæ—¶é—´æ­¥Dirichletåˆ†å¸ƒä¸­é‡‡æ ·ä¸€æ¡å®Œæ•´è½¨è¿¹ã€‚
        
        Returns:
            {timestep: probability_vector} æ¯ä¸ªæ—¶é—´æ­¥çš„æ¦‚ç‡åˆ†å¸ƒ
        """
        if agent_id not in self.agent_alphas:
            raise ValueError(f"Agent {agent_id} not initialized")
        
        trajectory = {}
        for timestep in range(1, self.horizon + 1):
            if timestep in self.agent_alphas[agent_id]:
                alpha = self.agent_alphas[agent_id][timestep]
                # ä»Dirichletåˆ†å¸ƒé‡‡æ ·
                prob_vector = np.random.dirichlet(alpha)
                trajectory[timestep] = prob_vector
        
        return trajectory

    def l1_radius(self, agent_id: int, timestep: int) -> float:
        """è®¡ç®—æ™ºèƒ½ä½“åœ¨æŒ‡å®šæ—¶é—´æ­¥çš„L1ç½®ä¿¡åŠå¾„ã€‚"""
        alpha = self.get_agent_alpha(agent_id, timestep)
        alpha_sum = alpha.sum()
        
        if alpha_sum <= 0:
            return float('inf')
        
        # è®¡ç®—L1ç½®ä¿¡åŠå¾„
        term1 = math.sqrt(math.log(2.0 / self.params.delta) / (2 * alpha_sum))
        term2 = math.log(2.0 / self.params.delta) / (3 * alpha_sum)
        
        return self.params.cK * (term1 + term2)


class OptimizedMultiTimestepSpatialDirichletBank:
    """ç»ˆæä¼˜åŒ–ç‰ˆæœ¬ï¼šç»´åº¦ä»…ç­‰äºå¯è¾¾é›†å¤§å°çš„å¤šæ—¶é—´æ­¥ç©ºé—´ç‹„åˆ©å…‹é›·é“¶è¡Œ
    
    æ ¸å¿ƒä¼˜åŒ–ï¼š
    1. æ¯ä¸ªæ—¶é—´æ­¥çš„Dirichletåˆ†å¸ƒç»´åº¦åªç­‰äºè¯¥æ—¶é—´æ­¥çš„å¯è¾¾é›†å¤§å°
    2. ç›´æ¥åœ¨å¯è¾¾é›†ä¸Šæ“ä½œï¼Œæ— éœ€åå¤„ç†
    3. æ”¯æŒé«˜æ•ˆçš„æœŸæœ›è®¡ç®—ï¼Œå®Œå…¨æ¶ˆé™¤é‡‡æ ·
    """

    def __init__(self, K: int, params: DirichletParams, horizon: Optional[int] = None) -> None:
        """åˆå§‹åŒ–ä¼˜åŒ–çš„å¤šæ—¶é—´æ­¥ç©ºé—´Dirichleté“¶è¡Œã€‚

        Args:
            K: ç½‘æ ¼å•å…ƒæ€»æ•°ï¼ˆç”¨äºå…¼å®¹æ€§ï¼Œå®é™…ç»´åº¦ä¼šåŠ¨æ€è°ƒæ•´ï¼‰
            params: Dirichletå‚æ•°é…ç½®
            horizon: æ—¶é—´èŒƒå›´ï¼ˆNone = ä»å…¨å±€é…ç½®è¯»å–ï¼‰
        """
        # Load horizon from global config if not specified
        if horizon is None:
            from c2o_drive.config import get_global_config
            horizon = get_global_config().time.default_horizon

        self.K = K
        self.params = params
        self.horizon = horizon
        
        # å­˜å‚¨æ¯ä¸ªagentåœ¨æ¯ä¸ªæ—¶é—´æ­¥çš„alphaå‚æ•°å’Œå¯è¾¾é›†
        # agent_alphas[agent_id][timestep] = np.array of size len(reachable_set)
        # agent_reachable_sets[agent_id][timestep] = List[int] å¯è¾¾é›†çš„cell indices
        self.agent_alphas: Dict[int, Dict[int, np.ndarray]] = {}
        self.agent_reachable_sets: Dict[int, Dict[int, List[int]]] = {}

    def init_agent(self, agent_id: int, reachable_sets: Dict[int, List[int]]) -> None:
        """ä¸ºæ™ºèƒ½ä½“åˆå§‹åŒ–ä¼˜åŒ–çš„Dirichletå…ˆéªŒåˆ†å¸ƒã€‚
        
        Args:
            agent_id: æ™ºèƒ½ä½“ID
            reachable_sets: {timestep: [reachable_cell_indices]} æ¯ä¸ªæ—¶é—´æ­¥çš„å¯è¾¾é›†
        """
        self.agent_alphas[agent_id] = {}
        self.agent_reachable_sets[agent_id] = {}
        
        # è®¡ç®—å‡åŒ€åˆ†é…çš„alpha_inå€¼
        for timestep, reachable in reachable_sets.items():
            if len(reachable) == 0:
                continue
                
            # å­˜å‚¨å¯è¾¾é›†
            self.agent_reachable_sets[agent_id][timestep] = reachable.copy()
            
            # åˆå§‹åŒ–alphaï¼šç»´åº¦åªç­‰äºå¯è¾¾é›†å¤§å°ï¼Œæ¯ä¸ªä½ç½®éƒ½æ˜¯alpha_in_per_cell
            alpha_in_per_cell = self.params.alpha_in / len(reachable)
            self.agent_alphas[agent_id][timestep] = np.full(len(reachable), alpha_in_per_cell)

    def update_with_softcount(self, agent_id: int, timestep: int, 
                            historical_cells: List[int], lr: float = 1.0) -> None:
        """ä½¿ç”¨å†å²æ•°æ®æ›´æ–°ä¼˜åŒ–çš„Dirichletåˆ†å¸ƒã€‚
        
        Args:
            agent_id: æ™ºèƒ½ä½“ID
            timestep: æ—¶é—´æ­¥
            historical_cells: å†å²è§‚æµ‹çš„cell indices
            lr: å­¦ä¹ ç‡
        """
        if agent_id not in self.agent_alphas:
            raise ValueError(f"Agent {agent_id} not initialized")
        
        if timestep not in self.agent_alphas[agent_id]:
            raise ValueError(f"Timestep {timestep} not initialized for agent {agent_id}")
        
        reachable_cells = self.agent_reachable_sets[agent_id][timestep]
        alpha = self.agent_alphas[agent_id][timestep]
        
        # æ„å»ºè½¯è®¡æ•°ï¼šåªå¯¹å¯è¾¾é›†å†…çš„å†å²æ•°æ®è®¡æ•°
        soft_count = np.zeros(len(reachable_cells))
        for cell in historical_cells:
            if cell in reachable_cells:
                idx = reachable_cells.index(cell)  # æ‰¾åˆ°åœ¨å¯è¾¾é›†ä¸­çš„ç´¢å¼•
                soft_count[idx] += lr

        # è®°å½•æ›´æ–°å‰çš„alphaç»Ÿè®¡
        alpha_before = alpha.sum()

        # æ›´æ–°alphaå‚æ•°
        self.agent_alphas[agent_id][timestep] += soft_count

        # è¯Šæ–­æ—¥å¿—ï¼šç›‘æ§alphaå¢é•¿
        alpha_after = self.agent_alphas[agent_id][timestep].sum()
        updated_cells = np.count_nonzero(soft_count)
        max_alpha = self.agent_alphas[agent_id][timestep].max()
        mean_alpha = self.agent_alphas[agent_id][timestep].mean()

        from c2o_drive.config import get_global_config
        if get_global_config().visualization.verbose_level >= 2:
            print(f"    [Dirichlet Update] Agent {agent_id}, t={timestep}:")
            print(f"      Alpha: {alpha_before:.2f} â†’ {alpha_after:.2f} (+{alpha_after-alpha_before:.2f})")
            print(f"      Updated cells: {updated_cells}/{len(reachable_cells)} "
                  f"(max_Î±={max_alpha:.2f}, mean_Î±={mean_alpha:.4f})")

    def sample_transition_distributions(self, agent_id: int, n_samples: int = 20) -> Dict[int, List[np.ndarray]]:
        """é‡‡æ ·å¤šä¸ªtransitionåˆ†å¸ƒç»„åˆï¼ˆå‘é‡åŒ–æ‰¹é‡é‡‡æ ·ç‰ˆæœ¬ï¼‰ã€‚

        Returns:
            {timestep: [prob_vector_1, prob_vector_2, ...]} æ¯ä¸ªæ ·æœ¬çš„æ¦‚ç‡åˆ†å¸ƒ
        """
        if agent_id not in self.agent_alphas:
            raise ValueError(f"Agent {agent_id} not initialized")

        distributions = {}
        for timestep in self.agent_alphas[agent_id]:
            alpha = self.agent_alphas[agent_id][timestep]

            # ğŸš€ ä¼˜åŒ–: ä½¿ç”¨numpyæ‰¹é‡é‡‡æ ·ï¼ˆçº¦1.2å€åŠ é€Ÿï¼‰
            # åŸå§‹ç‰ˆæœ¬: forå¾ªç¯n_samplesæ¬¡è°ƒç”¨np.random.dirichlet
            # ä¼˜åŒ–ç‰ˆæœ¬: ä¸€æ¬¡è°ƒç”¨ç”Ÿæˆ (n_samples, K) æ•°ç»„
            samples_array = np.random.dirichlet(alpha, size=n_samples)

            # ç›´æ¥å­˜å‚¨æ•°ç»„é¿å…listè½¬æ¢å¼€é”€
            distributions[timestep] = list(samples_array)

        return distributions

    def get_reachable_sets(self, agent_id: int) -> Dict[int, List[int]]:
        """è·å–æ™ºèƒ½ä½“çš„å¯è¾¾é›†ã€‚"""
        if agent_id not in self.agent_reachable_sets:
            raise ValueError(f"Agent {agent_id} not initialized")
        return self.agent_reachable_sets[agent_id].copy()

    def posterior_mean(self, agent_id: int, timestep: int) -> np.ndarray:
        """è®¡ç®—æ™ºèƒ½ä½“åœ¨æŒ‡å®šæ—¶é—´æ­¥çš„åéªŒå‡å€¼æ¦‚ç‡ï¼ˆåœ¨å®Œæ•´Kç»´ç©ºé—´ä¸­ï¼‰ã€‚"""
        if agent_id not in self.agent_alphas:
            raise ValueError(f"Agent {agent_id} not initialized")
        
        if timestep not in self.agent_alphas[agent_id]:
            raise ValueError(f"Timestep {timestep} not initialized for agent {agent_id}")
        
        # è·å–å¯è¾¾é›†ä¸Šçš„åéªŒå‡å€¼
        alpha = self.agent_alphas[agent_id][timestep]
        reachable_cells = self.agent_reachable_sets[agent_id][timestep]
        prob_reachable = alpha / alpha.sum()
        
        # æ˜ å°„åˆ°å®Œæ•´çš„Kç»´ç©ºé—´
        full_prob = np.zeros(self.K)
        for i, cell in enumerate(reachable_cells):
            full_prob[cell] = prob_reachable[i]
        
        return full_prob

    def get_agent_alpha(self, agent_id: int, timestep: int) -> np.ndarray:
        """è·å–æ™ºèƒ½ä½“åœ¨æŒ‡å®šæ—¶é—´æ­¥çš„alphaå‚æ•°ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰ã€‚"""
        if agent_id not in self.agent_alphas:
            raise ValueError(f"Agent {agent_id} not initialized")

        if timestep not in self.agent_alphas[agent_id]:
            raise ValueError(f"Timestep {timestep} not initialized for agent {agent_id}")

        return self.agent_alphas[agent_id][timestep].copy()

    def to_dict(self) -> Dict:
        """åºåˆ—åŒ–BankçŠ¶æ€ä¸ºå­—å…¸

        Returns:
            åŒ…å«æ‰€æœ‰å†…éƒ¨çŠ¶æ€çš„å­—å…¸
        """
        # åºåˆ—åŒ–alphaå‚æ•°ï¼ˆnumpyæ•°ç»„å°†åœ¨CheckpointManagerä¸­å¤„ç†ï¼‰
        agent_alphas_serialized = {}
        for agent_id, timesteps in self.agent_alphas.items():
            agent_alphas_serialized[agent_id] = {
                timestep: alpha for timestep, alpha in timesteps.items()
            }

        # åºåˆ—åŒ–å¯è¾¾é›†
        agent_reachable_sets_serialized = {}
        for agent_id, timesteps in self.agent_reachable_sets.items():
            agent_reachable_sets_serialized[agent_id] = {
                timestep: cells for timestep, cells in timesteps.items()
            }

        # åºåˆ—åŒ–å‚æ•°
        params_dict = {
            'alpha_in': self.params.alpha_in,
            'alpha_out': self.params.alpha_out,
            'delta': self.params.delta,
            'cK': self.params.cK
        }

        return {
            'K': self.K,
            'horizon': self.horizon,
            'params': params_dict,
            'agent_alphas': agent_alphas_serialized,
            'agent_reachable_sets': agent_reachable_sets_serialized
        }

    def sample_and_aggregate(
        self,
        agent_id: int,
        timestep: int,
        n_samples: int = 100
    ) -> Tuple[List[int], np.ndarray]:
        """é‡‡æ ·å¹¶å åŠ å¤šä¸ªtransitionåˆ†å¸ƒ

        ä»DirichletåéªŒé‡‡æ ·å¤šæ¬¡ï¼Œç„¶åå åŠ æ±‚å¹³å‡ï¼Œå¾—åˆ°aggregated probability distributionã€‚

        Args:
            agent_id: Agent ID
            timestep: Timestep (1-indexed)
            n_samples: é‡‡æ ·æ•°é‡

        Returns:
            reachable_cells: List of cell indices in reachable set
            aggregated_prob: å åŠ åçš„æ¦‚ç‡åˆ†å¸ƒï¼ˆå·²å½’ä¸€åŒ–ï¼‰
        """
        if agent_id not in self.agent_alphas:
            return [], np.array([])

        if timestep not in self.agent_alphas[agent_id]:
            return [], np.array([])

        alpha = self.agent_alphas[agent_id][timestep]
        reachable_cells = self.agent_reachable_sets[agent_id][timestep]

        # ä»DirichletåéªŒé‡‡æ ·
        samples = np.random.dirichlet(alpha, size=n_samples)

        # å åŠ ï¼ˆæ±‚å¹³å‡ï¼‰
        aggregated_prob = np.mean(samples, axis=0)

        # å½’ä¸€åŒ–ï¼ˆç¡®ä¿sum=1ï¼Œè™½ç„¶ç†è®ºä¸Šå·²ç»æ˜¯1ï¼‰
        prob_sum = np.sum(aggregated_prob)
        if prob_sum > 0:
            aggregated_prob = aggregated_prob / prob_sum

        return reachable_cells, aggregated_prob

    def get_confidence_set_from_samples(
        self,
        agent_id: int,
        timestep: int,
        confidence_level: float = 0.95,
        n_samples: int = 100
    ) -> List[int]:
        """åŸºäºé‡‡æ ·å åŠ è®¡ç®—confidence set

        æ”¯æŒåŠ¨æ€é‡‡æ ·ï¼šæ ¹æ®å¯è¾¾é›†å¤§å°è‡ªåŠ¨è°ƒæ•´é‡‡æ ·æ•°é‡

        ç®—æ³•æµç¨‹ï¼š
        1. ä»DirichletåéªŒé‡‡æ ·n_samplesæ¬¡ï¼ˆå¯èƒ½åŠ¨æ€è°ƒæ•´ï¼‰
        2. å åŠ æ‰€æœ‰é‡‡æ ·å¾—åˆ°aggregated probability
        3. æŒ‰æ¦‚ç‡é™åºé€‰æ‹©cellsï¼Œç´¯ç§¯æ¦‚ç‡è¾¾åˆ°confidence_levelæ—¶åœæ­¢

        Args:
            agent_id: Agent ID
            timestep: Timestep (1-indexed)
            confidence_level: ç½®ä¿¡æ°´å¹³ï¼ˆé»˜è®¤95%ï¼‰
            n_samples: åŸºç¡€é‡‡æ ·æ•°é‡

        Returns:
            confidence_set: åŒ…å«å‰X%æ¦‚ç‡è´¨é‡çš„cell indicesåˆ—è¡¨
        """
        from c2o_drive.config import get_global_config
        config = get_global_config()

        # è·å–å¯è¾¾é›†ä¿¡æ¯
        if agent_id not in self.agent_reachable_sets:
            return []
        if timestep not in self.agent_reachable_sets[agent_id]:
            return []

        reachable_cells = self.agent_reachable_sets[agent_id][timestep]
        reachable_set_size = len(reachable_cells)

        # åŠ¨æ€è°ƒæ•´é‡‡æ ·æ•°
        if config.safety.adaptive_sampling:
            # è®¡ç®—æ‰€éœ€é‡‡æ ·æ•°ï¼šç¡®ä¿æ¯ä¸ªcellè‡³å°‘è¢«é‡‡æ ·min_samples_per_cellæ¬¡
            required_samples = reachable_set_size * config.safety.min_samples_per_cell

            # å–æœ€å¤§å€¼ï¼ˆåŸºç¡€é‡‡æ ·æ•° vs è¦æ±‚é‡‡æ ·æ•°ï¼‰
            adjusted_samples = max(n_samples, required_samples)

            # åº”ç”¨ä¸Šé™ä¿æŠ¤
            adjusted_samples = min(adjusted_samples, config.safety.max_samples)

            # ä½¿ç”¨è°ƒæ•´åçš„é‡‡æ ·æ•°
            actual_samples = adjusted_samples
        else:
            # å›ºå®šé‡‡æ ·æ•°æ¨¡å¼
            actual_samples = n_samples

        # æ‰§è¡Œé‡‡æ ·å’Œå åŠ 
        reachable_cells, aggregated_prob = self.sample_and_aggregate(
            agent_id, timestep, actual_samples
        )

        if len(reachable_cells) == 0:
            return []

        # æŒ‰æ¦‚ç‡é™åºæ’åº
        sorted_indices = np.argsort(aggregated_prob)[::-1]

        # ç´¯ç§¯åˆ°è¾¾confidence_level
        confidence_set = []
        cumulative_prob = 0.0

        for idx in sorted_indices:
            cell_id = reachable_cells[idx]
            confidence_set.append(cell_id)
            cumulative_prob += aggregated_prob[idx]

            if cumulative_prob >= confidence_level:
                break

        return confidence_set

    def get_sampling_info(
        self,
        agent_id: int,
        timestep: int,
        n_samples: int = 100
    ) -> dict:
        """è·å–é‡‡æ ·ä¿¡æ¯ç”¨äºè°ƒè¯•

        Args:
            agent_id: Agent ID
            timestep: Timestep (1-indexed)
            n_samples: åŸºç¡€é‡‡æ ·æ•°é‡

        Returns:
            dict: {
                'reachable_set_size': int,
                'base_samples': int,
                'adjusted_samples': int,
                'samples_per_cell': float
            }
        """
        from c2o_drive.config import get_global_config
        config = get_global_config()

        if agent_id not in self.agent_reachable_sets:
            return {}
        if timestep not in self.agent_reachable_sets[agent_id]:
            return {}

        reachable_set_size = len(self.agent_reachable_sets[agent_id][timestep])

        if config.safety.adaptive_sampling:
            required_samples = reachable_set_size * config.safety.min_samples_per_cell
            adjusted_samples = max(n_samples, required_samples)
            adjusted_samples = min(adjusted_samples, config.safety.max_samples)
        else:
            adjusted_samples = n_samples

        return {
            'reachable_set_size': reachable_set_size,
            'base_samples': n_samples,
            'adjusted_samples': adjusted_samples,
            'samples_per_cell': adjusted_samples / reachable_set_size if reachable_set_size > 0 else 0
        }

    @staticmethod
    def from_dict(data: Dict) -> 'OptimizedMultiTimestepSpatialDirichletBank':
        """ä»å­—å…¸æ¢å¤BankçŠ¶æ€

        Args:
            data: åºåˆ—åŒ–çš„å­—å…¸

        Returns:
            æ¢å¤çš„Bankå®ä¾‹
        """
        # æ¢å¤å‚æ•°
        params = DirichletParams(
            alpha_in=data['params']['alpha_in'],
            alpha_out=data['params']['alpha_out'],
            delta=data['params']['delta'],
            cK=data['params']['cK']
        )

        # åˆ›å»ºBankå®ä¾‹
        bank = OptimizedMultiTimestepSpatialDirichletBank(
            K=data['K'],
            params=params,
            horizon=data['horizon']
        )

        # æ¢å¤agent_alphasï¼ˆnumpyæ•°ç»„ï¼‰
        for agent_id, timesteps in data['agent_alphas'].items():
            agent_id_int = int(agent_id)
            bank.agent_alphas[agent_id_int] = {}
            for timestep, alpha in timesteps.items():
                timestep_int = int(timestep)
                # alphaåº”è¯¥å·²ç»æ˜¯numpyæ•°ç»„
                bank.agent_alphas[agent_id_int][timestep_int] = alpha

        # æ¢å¤agent_reachable_sets
        for agent_id, timesteps in data['agent_reachable_sets'].items():
            agent_id_int = int(agent_id)
            bank.agent_reachable_sets[agent_id_int] = {}
            for timestep, cells in timesteps.items():
                timestep_int = int(timestep)
                bank.agent_reachable_sets[agent_id_int][timestep_int] = list(cells)

        return bank
