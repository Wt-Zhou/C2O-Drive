"""
è®­ç»ƒçŠ¶æ€çš„Checkpointç®¡ç†å™¨

æ”¯æŒä¿å­˜å’ŒåŠ è½½å®Œæ•´çš„è®­ç»ƒçŠ¶æ€ï¼ŒåŒ…æ‹¬ï¼š
- TrajectoryBufferï¼ˆå†å²è½¨è¿¹æ•°æ®ï¼‰
- DirichletBankï¼ˆå­¦ä¹ åˆ°çš„å…ˆéªŒåˆ†å¸ƒï¼‰
- QDistributionTrackerï¼ˆQå€¼åˆ†å¸ƒå†å²ï¼‰
- è®­ç»ƒè¿›åº¦å’Œéšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€
"""

from __future__ import annotations
import json
import hashlib
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime


class CheckpointManager:
    """è®­ç»ƒcheckpointç®¡ç†å™¨"""

    CHECKPOINT_VERSION = "1.0.0"

    def __init__(self, checkpoint_dir: str = "checkpoints"):
        """åˆå§‹åŒ–checkpointç®¡ç†å™¨

        Args:
            checkpoint_dir: checkpointä¿å­˜çš„æ ¹ç›®å½•
        """
        self.checkpoint_dir = Path(checkpoint_dir)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)

    def save_checkpoint(self,
                       episode_id: int,
                       trajectory_buffer,
                       dirichlet_bank,
                       q_tracker,
                       config: Dict[str, Any],
                       rng_state: Optional[Dict] = None,
                       metadata: Optional[Dict[str, Any]] = None) -> Path:
        """ä¿å­˜å®Œæ•´çš„è®­ç»ƒcheckpoint

        Args:
            episode_id: å½“å‰episodeç¼–å·
            trajectory_buffer: TrajectoryBufferå®ä¾‹
            dirichlet_bank: DirichletBankå®ä¾‹
            q_tracker: QDistributionTrackerå®ä¾‹
            config: å…¨å±€é…ç½®å­—å…¸
            rng_state: éšæœºæ•°ç”Ÿæˆå™¨çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
            metadata: é¢å¤–çš„å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰

        Returns:
            checkpointç›®å½•è·¯å¾„
        """
        # åˆ›å»ºcheckpointç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        checkpoint_name = f"checkpoint_ep{episode_id:04d}_{timestamp}"
        checkpoint_path = self.checkpoint_dir / checkpoint_name
        checkpoint_path.mkdir(parents=True, exist_ok=True)

        print(f"\nğŸ’¾ ä¿å­˜checkpoint: {checkpoint_name}")

        # 1. ä¿å­˜å…ƒæ•°æ®
        config_hash = self._compute_config_hash(config)
        meta = {
            "version": self.CHECKPOINT_VERSION,
            "episode_id": episode_id,
            "timestamp": timestamp,
            "config_hash": config_hash,
            **(metadata or {})
        }
        with open(checkpoint_path / "metadata.json", "w") as f:
            json.dump(meta, f, indent=2)

        # 2. ä¿å­˜é…ç½®
        with open(checkpoint_path / "config.json", "w") as f:
            json.dump(config, f, indent=2)

        # 3. ä¿å­˜TrajectoryBuffer
        self._save_trajectory_buffer(trajectory_buffer, checkpoint_path)

        # 4. ä¿å­˜DirichletBank
        self._save_dirichlet_bank(dirichlet_bank, checkpoint_path)

        # 5. ä¿å­˜QDistributionTracker
        q_tracker.save_data(str(checkpoint_path / "q_tracker.json"))

        # 6. ä¿å­˜è®­ç»ƒçŠ¶æ€
        training_state = {
            "episode_id": episode_id,
            "rng_state": rng_state
        }
        with open(checkpoint_path / "training_state.json", "w") as f:
            json.dump(training_state, f, indent=2)

        print(f"âœ… Checkpointå·²ä¿å­˜åˆ°: {checkpoint_path}")
        return checkpoint_path

    def load_checkpoint(self, checkpoint_path: str) -> Dict[str, Any]:
        """åŠ è½½è®­ç»ƒcheckpoint

        Args:
            checkpoint_path: checkpointç›®å½•è·¯å¾„

        Returns:
            åŒ…å«æ‰€æœ‰çŠ¶æ€çš„å­—å…¸
        """
        checkpoint_path = Path(checkpoint_path)

        if not checkpoint_path.exists():
            raise FileNotFoundError(f"Checkpointä¸å­˜åœ¨: {checkpoint_path}")

        print(f"\nğŸ“‚ åŠ è½½checkpoint: {checkpoint_path.name}")

        # 1. åŠ è½½å…ƒæ•°æ®
        with open(checkpoint_path / "metadata.json", "r") as f:
            metadata = json.load(f)

        version = metadata.get("version", "unknown")
        if version != self.CHECKPOINT_VERSION:
            print(f"âš ï¸  è­¦å‘Š: Checkpointç‰ˆæœ¬ä¸åŒ¹é… (æœŸæœ› {self.CHECKPOINT_VERSION}, å®é™… {version})")

        # 2. åŠ è½½é…ç½®
        with open(checkpoint_path / "config.json", "r") as f:
            config = json.load(f)

        # 3. åŠ è½½TrajectoryBufferçŠ¶æ€
        trajectory_buffer_data = self._load_trajectory_buffer(checkpoint_path)

        # 4. åŠ è½½DirichletBankçŠ¶æ€
        dirichlet_bank_data = self._load_dirichlet_bank(checkpoint_path)

        # 5. åŠ è½½QDistributionTrackerçŠ¶æ€
        with open(checkpoint_path / "q_tracker.json", "r") as f:
            q_tracker_data = json.load(f)

        # 6. åŠ è½½è®­ç»ƒçŠ¶æ€
        with open(checkpoint_path / "training_state.json", "r") as f:
            training_state = json.load(f)

        print(f"âœ… Checkpointå·²åŠ è½½ (Episode {metadata['episode_id']})")

        return {
            "metadata": metadata,
            "config": config,
            "trajectory_buffer_data": trajectory_buffer_data,
            "dirichlet_bank_data": dirichlet_bank_data,
            "q_tracker_data": q_tracker_data,
            "training_state": training_state
        }

    def list_checkpoints(self) -> List[Path]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„checkpoint"""
        checkpoints = sorted(self.checkpoint_dir.glob("checkpoint_ep*"))
        return checkpoints

    def _save_trajectory_buffer(self, buffer, checkpoint_path: Path):
        """ä¿å­˜TrajectoryBufferçŠ¶æ€"""
        buffer_dict = buffer.to_dict()

        # åˆ†ç¦»numpyæ•°ç»„å’Œå…ƒæ•°æ®
        numpy_arrays = {}
        metadata = {}

        for key, value in buffer_dict.items():
            if isinstance(value, np.ndarray):
                numpy_arrays[key] = value
            else:
                metadata[key] = value

        # ä¿å­˜numpyæ•°ç»„
        if numpy_arrays:
            np.savez_compressed(checkpoint_path / "trajectory_buffer.npz", **numpy_arrays)

        # ä¿å­˜å…ƒæ•°æ®
        with open(checkpoint_path / "trajectory_buffer_meta.json", "w") as f:
            json.dump(metadata, f, indent=2)

    def _load_trajectory_buffer(self, checkpoint_path: Path) -> Dict[str, Any]:
        """åŠ è½½TrajectoryBufferçŠ¶æ€"""
        # åŠ è½½å…ƒæ•°æ®
        with open(checkpoint_path / "trajectory_buffer_meta.json", "r") as f:
            metadata = json.load(f)

        # åŠ è½½numpyæ•°ç»„
        npz_path = checkpoint_path / "trajectory_buffer.npz"
        numpy_data = {}
        if npz_path.exists():
            with np.load(npz_path, allow_pickle=True) as data:
                numpy_data = {key: data[key] for key in data.keys()}

        return {**metadata, **numpy_data}

    def _save_dirichlet_bank(self, bank, checkpoint_path: Path):
        """ä¿å­˜DirichletBankçŠ¶æ€"""
        bank_dict = bank.to_dict()

        # ä¿å­˜alphaæ•°ç»„ï¼ˆä½¿ç”¨npzå‹ç¼©æ ¼å¼ï¼‰
        alpha_arrays = {}
        for agent_id, timesteps in bank_dict["agent_alphas"].items():
            for timestep, alpha in timesteps.items():
                key = f"agent_{agent_id}_t_{timestep}"
                alpha_arrays[key] = alpha

        np.savez_compressed(checkpoint_path / "dirichlet_bank.npz", **alpha_arrays)

        # ä¿å­˜å…¶ä»–å…ƒæ•°æ®ï¼ˆä¸åŒ…æ‹¬numpyæ•°ç»„ï¼‰
        metadata = {
            "K": bank_dict["K"],
            "horizon": bank_dict["horizon"],
            "params": bank_dict["params"],
            "agent_reachable_sets": bank_dict["agent_reachable_sets"]
        }

        with open(checkpoint_path / "dirichlet_bank_meta.json", "w") as f:
            json.dump(metadata, f, indent=2)

    def _load_dirichlet_bank(self, checkpoint_path: Path) -> Dict[str, Any]:
        """åŠ è½½DirichletBankçŠ¶æ€"""
        # åŠ è½½å…ƒæ•°æ®
        with open(checkpoint_path / "dirichlet_bank_meta.json", "r") as f:
            metadata = json.load(f)

        # åŠ è½½alphaæ•°ç»„
        agent_alphas = {}
        with np.load(checkpoint_path / "dirichlet_bank.npz") as data:
            for key in data.keys():
                # è§£ækey: "agent_{agent_id}_t_{timestep}"
                parts = key.split("_")
                agent_id = int(parts[1])
                timestep = int(parts[3])

                if agent_id not in agent_alphas:
                    agent_alphas[agent_id] = {}
                agent_alphas[agent_id][timestep] = data[key]

        return {
            **metadata,
            "agent_alphas": agent_alphas
        }

    def _compute_config_hash(self, config: Dict[str, Any]) -> str:
        """è®¡ç®—é…ç½®çš„hashå€¼ç”¨äºç‰ˆæœ¬æ§åˆ¶"""
        config_str = json.dumps(config, sort_keys=True)
        return hashlib.md5(config_str.encode()).hexdigest()[:16]
